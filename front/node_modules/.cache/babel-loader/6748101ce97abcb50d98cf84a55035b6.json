{"ast":null,"code":"import _regeneratorRuntime from \"C:\\\\Users\\\\JUN-D\\\\Desktop\\\\HELF-master\\\\front\\\\node_modules\\\\babel-preset-react-app\\\\node_modules\\\\@babel\\\\runtime/regenerator\";\nimport _asyncToGenerator from \"C:\\\\Users\\\\JUN-D\\\\Desktop\\\\HELF-master\\\\front\\\\node_modules\\\\babel-preset-react-app\\\\node_modules\\\\@babel\\\\runtime/helpers/esm/asyncToGenerator\";\nimport _slicedToArray from \"C:\\\\Users\\\\JUN-D\\\\Desktop\\\\HELF-master\\\\front\\\\node_modules\\\\babel-preset-react-app\\\\node_modules\\\\@babel\\\\runtime/helpers/esm/slicedToArray\";\n\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { env } from '../environment';\nimport { FromPixels } from '../kernel_names';\nimport { getKernel } from '../kernel_registry';\nimport { Tensor } from '../tensor';\nimport { convertToTensor } from '../tensor_util_env';\nimport { cast } from './cast';\nimport { op } from './operation';\nimport { tensor3d } from './tensor3d';\nvar fromPixels2DContext;\n/**\n * Creates a `tf.Tensor` from an image.\n *\n * ```js\n * const image = new ImageData(1, 1);\n * image.data[0] = 100;\n * image.data[1] = 150;\n * image.data[2] = 200;\n * image.data[3] = 255;\n *\n * tf.browser.fromPixels(image).print();\n * ```\n *\n * @param pixels The input image to construct the tensor from. The\n * supported image types are all 4-channel. You can also pass in an image\n * object with following attributes:\n * `{data: Uint8Array; width: number; height: number}`\n * @param numChannels The number of channels of the output tensor. A\n * numChannels value less than 4 allows you to ignore channels. Defaults to\n * 3 (ignores alpha channel of input image).\n *\n * @returns A Tensor3D with the shape `[height, width, numChannels]`.\n *\n * Note: fromPixels can be lossy in some cases, same image may result in\n * slightly different tensor values, if rendered by different rendering\n * engines. This means that results from different browsers, or even same\n * browser with CPU and GPU rendering engines can be different. See discussion\n * in details:\n * https://github.com/tensorflow/tfjs/issues/5482\n *\n * @doc {heading: 'Browser', namespace: 'browser', ignoreCI: true}\n */\n\nfunction fromPixels_(pixels) {\n  var numChannels = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 3;\n\n  // Sanity checks.\n  if (numChannels > 4) {\n    throw new Error('Cannot construct Tensor with more than 4 channels from pixels.');\n  }\n\n  if (pixels == null) {\n    throw new Error('pixels passed to tf.browser.fromPixels() can not be null');\n  }\n\n  var isPixelData = false;\n  var isImageData = false;\n  var isVideo = false;\n  var isImage = false;\n  var isCanvasLike = false;\n  var isImageBitmap = false;\n\n  if (pixels.data instanceof Uint8Array) {\n    isPixelData = true;\n  } else if (typeof ImageData !== 'undefined' && pixels instanceof ImageData) {\n    isImageData = true;\n  } else if (typeof HTMLVideoElement !== 'undefined' && pixels instanceof HTMLVideoElement) {\n    isVideo = true;\n  } else if (typeof HTMLImageElement !== 'undefined' && pixels instanceof HTMLImageElement) {\n    isImage = true; // tslint:disable-next-line: no-any\n  } else if (pixels.getContext != null) {\n    isCanvasLike = true;\n  } else if (typeof ImageBitmap !== 'undefined' && pixels instanceof ImageBitmap) {\n    isImageBitmap = true;\n  } else {\n    throw new Error('pixels passed to tf.browser.fromPixels() must be either an ' + \"HTMLVideoElement, HTMLImageElement, HTMLCanvasElement, ImageData \" + \"in browser, or OffscreenCanvas, ImageData in webworker\" + \" or {data: Uint32Array, width: number, height: number}, \" + \"but was \".concat(pixels.constructor.name));\n  }\n\n  if (isVideo) {\n    var HAVE_CURRENT_DATA_READY_STATE = 2;\n\n    if (isVideo && pixels.readyState < HAVE_CURRENT_DATA_READY_STATE) {\n      throw new Error('The video element has not loaded data yet. Please wait for ' + '`loadeddata` event on the <video> element.');\n    }\n  } // If the current backend has 'FromPixels' registered, it has a more\n  // efficient way of handling pixel uploads, so we call that.\n\n\n  var kernel = getKernel(FromPixels, ENGINE.backendName);\n\n  if (kernel != null) {\n    var inputs = {\n      pixels: pixels\n    };\n    var attrs = {\n      numChannels: numChannels\n    };\n    return ENGINE.runKernel(FromPixels, inputs, attrs);\n  }\n\n  var _ref = isVideo ? [pixels.videoWidth, pixels.videoHeight] : [pixels.width, pixels.height],\n      _ref2 = _slicedToArray(_ref, 2),\n      width = _ref2[0],\n      height = _ref2[1];\n\n  var vals;\n\n  if (isCanvasLike) {\n    vals = // tslint:disable-next-line:no-any\n    pixels.getContext('2d').getImageData(0, 0, width, height).data;\n  } else if (isImageData || isPixelData) {\n    vals = pixels.data;\n  } else if (isImage || isVideo || isImageBitmap) {\n    if (fromPixels2DContext == null) {\n      if (typeof document === 'undefined') {\n        if (typeof OffscreenCanvas !== 'undefined' && typeof OffscreenCanvasRenderingContext2D !== 'undefined') {\n          // @ts-ignore\n          fromPixels2DContext = new OffscreenCanvas(1, 1).getContext('2d');\n        } else {\n          throw new Error('Cannot parse input in current context. ' + 'Reason: OffscreenCanvas Context2D rendering is not supported.');\n        }\n      } else {\n        fromPixels2DContext = document.createElement('canvas').getContext('2d');\n      }\n    }\n\n    fromPixels2DContext.canvas.width = width;\n    fromPixels2DContext.canvas.height = height;\n    fromPixels2DContext.drawImage(pixels, 0, 0, width, height);\n    vals = fromPixels2DContext.getImageData(0, 0, width, height).data;\n  }\n\n  var values;\n\n  if (numChannels === 4) {\n    values = new Int32Array(vals);\n  } else {\n    var numPixels = width * height;\n    values = new Int32Array(numPixels * numChannels);\n\n    for (var i = 0; i < numPixels; i++) {\n      for (var channel = 0; channel < numChannels; ++channel) {\n        values[i * numChannels + channel] = vals[i * 4 + channel];\n      }\n    }\n  }\n\n  var outShape = [height, width, numChannels];\n  return tensor3d(values, outShape, 'int32');\n} // Helper functions for |fromPixelsAsync| to check whether the input can\n// be wrapped into imageBitmap.\n\n\nfunction isPixelData(pixels) {\n  return pixels != null && pixels.data instanceof Uint8Array;\n}\n\nfunction isImageBitmapFullySupported() {\n  return typeof window !== 'undefined' && typeof ImageBitmap !== 'undefined' && window.hasOwnProperty('createImageBitmap');\n}\n\nfunction isNonEmptyPixels(pixels) {\n  return pixels != null && pixels.width !== 0 && pixels.height !== 0;\n}\n\nfunction canWrapPixelsToImageBitmap(pixels) {\n  return isImageBitmapFullySupported() && !(pixels instanceof ImageBitmap) && isNonEmptyPixels(pixels) && !isPixelData(pixels);\n}\n/**\n * Creates a `tf.Tensor` from an image in async way.\n *\n * ```js\n * const image = new ImageData(1, 1);\n * image.data[0] = 100;\n * image.data[1] = 150;\n * image.data[2] = 200;\n * image.data[3] = 255;\n *\n * (await tf.browser.fromPixelsAsync(image)).print();\n * ```\n * This API is the async version of fromPixels. The API will first\n * check |WRAP_TO_IMAGEBITMAP| flag, and try to wrap the input to\n * imageBitmap if the flag is set to true.\n *\n * @param pixels The input image to construct the tensor from. The\n * supported image types are all 4-channel. You can also pass in an image\n * object with following attributes:\n * `{data: Uint8Array; width: number; height: number}`\n * @param numChannels The number of channels of the output tensor. A\n * numChannels value less than 4 allows you to ignore channels. Defaults to\n * 3 (ignores alpha channel of input image).\n *\n * @doc {heading: 'Browser', namespace: 'browser', ignoreCI: true}\n */\n\n\nexport function fromPixelsAsync(_x) {\n  return _fromPixelsAsync.apply(this, arguments);\n}\n/**\n * Draws a `tf.Tensor` of pixel values to a byte array or optionally a\n * canvas.\n *\n * When the dtype of the input is 'float32', we assume values in the range\n * [0-1]. Otherwise, when input is 'int32', we assume values in the range\n * [0-255].\n *\n * Returns a promise that resolves when the canvas has been drawn to.\n *\n * @param img A rank-2 tensor with shape `[height, width]`, or a rank-3 tensor\n * of shape `[height, width, numChannels]`. If rank-2, draws grayscale. If\n * rank-3, must have depth of 1, 3 or 4. When depth of 1, draws\n * grayscale. When depth of 3, we draw with the first three components of\n * the depth dimension corresponding to r, g, b and alpha = 1. When depth of\n * 4, all four components of the depth dimension correspond to r, g, b, a.\n * @param canvas The canvas to draw to.\n *\n * @doc {heading: 'Browser', namespace: 'browser'}\n */\n\nfunction _fromPixelsAsync() {\n  _fromPixelsAsync = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee(pixels) {\n    var numChannels,\n        inputs,\n        imageBitmap,\n        _args = arguments;\n    return _regeneratorRuntime.wrap(function _callee$(_context) {\n      while (1) {\n        switch (_context.prev = _context.next) {\n          case 0:\n            numChannels = _args.length > 1 && _args[1] !== undefined ? _args[1] : 3;\n            inputs = null; // Check whether the backend needs to wrap |pixels| to imageBitmap and\n            // whether |pixels| can be wrapped to imageBitmap.\n\n            if (!(env().getBool('WRAP_TO_IMAGEBITMAP') && canWrapPixelsToImageBitmap(pixels))) {\n              _context.next = 15;\n              break;\n            }\n\n            _context.prev = 3;\n            _context.next = 6;\n            return createImageBitmap(pixels, {\n              premultiplyAlpha: 'none'\n            });\n\n          case 6:\n            imageBitmap = _context.sent;\n            _context.next = 12;\n            break;\n\n          case 9:\n            _context.prev = 9;\n            _context.t0 = _context[\"catch\"](3);\n            imageBitmap = null;\n\n          case 12:\n            // createImageBitmap will clip the source size.\n            // In some cases, the input will have larger size than its content.\n            // E.g. new Image(10, 10) but with 1 x 1 content. Using\n            // createImageBitmap will clip the size from 10 x 10 to 1 x 1, which\n            // is not correct. We should avoid wrapping such resouce to\n            // imageBitmap.\n            if (imageBitmap != null && imageBitmap.width === pixels.width && imageBitmap.height === pixels.height) {\n              inputs = imageBitmap;\n            } else {\n              inputs = pixels;\n            }\n\n            _context.next = 16;\n            break;\n\n          case 15:\n            inputs = pixels;\n\n          case 16:\n            return _context.abrupt(\"return\", fromPixels_(inputs, numChannels));\n\n          case 17:\n          case \"end\":\n            return _context.stop();\n        }\n      }\n    }, _callee, null, [[3, 9]]);\n  }));\n  return _fromPixelsAsync.apply(this, arguments);\n}\n\nexport function toPixels(_x2, _x3) {\n  return _toPixels.apply(this, arguments);\n}\n\nfunction _toPixels() {\n  _toPixels = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee2(img, canvas) {\n    var $img, originalImgTensor, _$img$shape$slice, _$img$shape$slice2, height, width, depth, data, multiplier, bytes, i, rgba, d, value, j, ctx, imageData;\n\n    return _regeneratorRuntime.wrap(function _callee2$(_context2) {\n      while (1) {\n        switch (_context2.prev = _context2.next) {\n          case 0:\n            $img = convertToTensor(img, 'img', 'toPixels');\n\n            if (!(img instanceof Tensor)) {\n              // Assume int32 if user passed a native array.\n              originalImgTensor = $img;\n              $img = cast(originalImgTensor, 'int32');\n              originalImgTensor.dispose();\n            }\n\n            if (!($img.rank !== 2 && $img.rank !== 3)) {\n              _context2.next = 4;\n              break;\n            }\n\n            throw new Error(\"toPixels only supports rank 2 or 3 tensors, got rank \".concat($img.rank, \".\"));\n\n          case 4:\n            _$img$shape$slice = $img.shape.slice(0, 2), _$img$shape$slice2 = _slicedToArray(_$img$shape$slice, 2), height = _$img$shape$slice2[0], width = _$img$shape$slice2[1];\n            depth = $img.rank === 2 ? 1 : $img.shape[2];\n\n            if (!(depth > 4 || depth === 2)) {\n              _context2.next = 8;\n              break;\n            }\n\n            throw new Error(\"toPixels only supports depth of size \" + \"1, 3 or 4 but got \".concat(depth));\n\n          case 8:\n            if (!($img.dtype !== 'float32' && $img.dtype !== 'int32')) {\n              _context2.next = 10;\n              break;\n            }\n\n            throw new Error(\"Unsupported type for toPixels: \".concat($img.dtype, \".\") + \" Please use float32 or int32 tensors.\");\n\n          case 10:\n            _context2.next = 12;\n            return $img.data();\n\n          case 12:\n            data = _context2.sent;\n            multiplier = $img.dtype === 'float32' ? 255 : 1;\n            bytes = new Uint8ClampedArray(width * height * 4);\n            i = 0;\n\n          case 16:\n            if (!(i < height * width)) {\n              _context2.next = 41;\n              break;\n            }\n\n            rgba = [0, 0, 0, 255];\n            d = 0;\n\n          case 19:\n            if (!(d < depth)) {\n              _context2.next = 33;\n              break;\n            }\n\n            value = data[i * depth + d];\n\n            if (!($img.dtype === 'float32')) {\n              _context2.next = 26;\n              break;\n            }\n\n            if (!(value < 0 || value > 1)) {\n              _context2.next = 24;\n              break;\n            }\n\n            throw new Error(\"Tensor values for a float32 Tensor must be in the \" + \"range [0 - 1] but encountered \".concat(value, \".\"));\n\n          case 24:\n            _context2.next = 29;\n            break;\n\n          case 26:\n            if (!($img.dtype === 'int32')) {\n              _context2.next = 29;\n              break;\n            }\n\n            if (!(value < 0 || value > 255)) {\n              _context2.next = 29;\n              break;\n            }\n\n            throw new Error(\"Tensor values for a int32 Tensor must be in the \" + \"range [0 - 255] but encountered \".concat(value, \".\"));\n\n          case 29:\n            if (depth === 1) {\n              rgba[0] = value * multiplier;\n              rgba[1] = value * multiplier;\n              rgba[2] = value * multiplier;\n            } else {\n              rgba[d] = value * multiplier;\n            }\n\n          case 30:\n            d++;\n            _context2.next = 19;\n            break;\n\n          case 33:\n            j = i * 4;\n            bytes[j + 0] = Math.round(rgba[0]);\n            bytes[j + 1] = Math.round(rgba[1]);\n            bytes[j + 2] = Math.round(rgba[2]);\n            bytes[j + 3] = Math.round(rgba[3]);\n\n          case 38:\n            ++i;\n            _context2.next = 16;\n            break;\n\n          case 41:\n            if (canvas != null) {\n              canvas.width = width;\n              canvas.height = height;\n              ctx = canvas.getContext('2d');\n              imageData = new ImageData(bytes, width, height);\n              ctx.putImageData(imageData, 0, 0);\n            }\n\n            if ($img !== img) {\n              $img.dispose();\n            }\n\n            return _context2.abrupt(\"return\", bytes);\n\n          case 44:\n          case \"end\":\n            return _context2.stop();\n        }\n      }\n    }, _callee2);\n  }));\n  return _toPixels.apply(this, arguments);\n}\n\nexport var fromPixels = op({\n  fromPixels_: fromPixels_\n});","map":null,"metadata":{},"sourceType":"module"}